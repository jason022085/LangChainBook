{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們將定義一個查詢模式，希望我們的模型輸出。為了使我們的查詢分析更有趣，我們將添加一個sub_queries字段，其中包含從頂層問題派生的更具體的問題。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "sub_queries_description = \"\"\"\\\n",
    "If the original question contains multiple distinct sub-questions, \\\n",
    "or if there are more generic questions that would be helpful to answer in \\\n",
    "order to answer the original question, write a list of all relevant sub-questions. \\\n",
    "Make sure this list is comprehensive and covers all parts of the original question. \\\n",
    "It's ok if there's redundancy in the sub-questions. \\\n",
    "Make sure the sub-questions are as narrowly focused as possible.\"\"\"\n",
    "\n",
    "\n",
    "class Search(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"Primary similarity search query applied to video transcripts.\",\n",
    "    )\n",
    "    sub_queries: List[str] = Field(\n",
    "        default_factory=list, description=sub_queries_description\n",
    "    )\n",
    "    publish_year: Optional[int] = Field(None, description=\"Year video was published\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "system = \"\"\"You are a senior programming language expert. \\\n",
    "Given a question, return a list of answers the most relevant results.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        MessagesPlaceholder(\"examples\", optional=True),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOllama(model='llama3.2:3b')\n",
    "structured_llm = llm.with_structured_output(Search)\n",
    "query_analyzer = {\"question\": RunnablePassthrough()} | prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search(query='Python vs C', sub_queries=['object-oriented programming language', 'difference in syntax', 'memory management'], publish_year=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不使用任何範例\n",
    "query_analyzer.invoke(\n",
    "    \"what's the difference between Python and C? do both are object-oriented programming?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新增範例和調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's chat langchain, is it a langchain template?\"\n",
    "query = Search(\n",
    "    query=\"What is chat langchain and is it a langchain template?\",\n",
    "    sub_queries=[\"What is chat langchain\", \"What is a langchain template\"],\n",
    ")\n",
    "examples.append({\"input\": question, \"tool_calls\": [query]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How to build multi-agent system and stream intermediate steps from it\"\n",
    "query = Search(\n",
    "    query=\"How to build multi-agent system and stream intermediate steps from it\",\n",
    "    sub_queries=[\n",
    "        \"How to build multi-agent system\",\n",
    "        \"How to stream intermediate steps from multi-agent system\",\n",
    "        \"How to stream intermediate steps\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples.append({\"input\": question, \"tool_calls\": [query]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"LangChain agents vs LangGraph?\"\n",
    "query = Search(\n",
    "    query=\"What's the difference between LangChain agents and LangGraph? How do you deploy them?\",\n",
    "    sub_queries=[\n",
    "        \"What are LangChain agents\",\n",
    "        \"What is LangGraph\",\n",
    "        \"How do you deploy LangChain agents\",\n",
    "        \"How do you deploy LangGraph\",\n",
    "    ],\n",
    ")\n",
    "examples.append({\"input\": question, \"tool_calls\": [query]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    ")\n",
    "\n",
    "\n",
    "def tool_example_to_messages(example: Dict) -> List[BaseMessage]:\n",
    "    messages: List[BaseMessage] = [HumanMessage(content=example[\"input\"])]\n",
    "    openai_tool_calls = []\n",
    "    for tool_call in example[\"tool_calls\"]:\n",
    "        openai_tool_calls.append(\n",
    "            {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool_call.__class__.__name__,\n",
    "                    \"arguments\": tool_call.json(),\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    messages.append(\n",
    "        AIMessage(content=\"\", additional_kwargs={\"tool_calls\": openai_tool_calls})\n",
    "    )\n",
    "    tool_outputs = example.get(\"tool_outputs\") or [\n",
    "        \"You have correctly called this tool.\"\n",
    "    ] * len(openai_tool_calls)\n",
    "    for output, tool_call in zip(tool_outputs, openai_tool_calls):\n",
    "        messages.append(ToolMessage(content=output, tool_call_id=tool_call[\"id\"]))\n",
    "    return messages\n",
    "\n",
    "\n",
    "example_msgs = [msg for ex in examples for msg in tool_example_to_messages(ex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "query_analyzer_with_examples = (\n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | prompt.partial(examples=example_msgs)\n",
    "    | structured_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search(query=\"What's the difference between Python and C? Do both are object-oriented programming\", sub_queries=['What is the difference between Python and C', 'Is Python object-oriented programming', 'Is C object-oriented programming'], publish_year=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subquery更專注於query本身\n",
    "query_analyzer_with_examples.invoke(\n",
    "    \"what's the difference between Python and C? do both are object-oriented programming?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
